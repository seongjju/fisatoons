# ëª¨ë¸ë³„ ì˜ˆì¸¡ ì„±ëŠ¥ (í›ˆë ¨ ë°ì´í„° ê¸°ë°˜)

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras.callbacks import EarlyStopping

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°(ì‹¤ì œ ë³„ì  í¬í•¨)
data = pd.read_csv("finetuned_sentiment_results.csv")

# íŠ¹ì„±(X)ê³¼ íƒ€ê²Ÿ(y) ì„¤ì •
X = data[['ê¸ì •ë¹„ìœ¨', 'ë¶€ì •ë¹„ìœ¨']]
y = data['ì‹¤ì œë³„ì ']  # ëª¨ë¸ì´ ì˜ˆì¸¡í•  ë³„ì  (í›ˆë ¨ìš©)

# í•™ìŠµ ë°ì´í„° ë¶„ë¦¬(train-test split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)

# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

# ë°ì´í„° ì •ê·œí™” (LSTMì„ ìœ„í•´ MinMax Scaling ì ìš©)
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# LSTM ì…ë ¥ í˜•íƒœ ë³€í™˜
X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))

# LSTM ëª¨ë¸ êµ¬ì„± - ê¸°ë³¸ Dropout ì ìš©
# LSTM MSE: 0.0377, RMSE: 0.1942, RÂ²: 0.1501
lstm_model = Sequential([
    LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)),
    Dropout(0.2),
    LSTM(50, activation='relu'),
    Dropout(0.2),
    Dense(1)
])

# # ëª¨ë¸ ì»´íŒŒì¼ (í•™ìŠµ ì „ì— ìˆ˜í–‰)
# LSTM MSE: 0.0377, RMSE: 0.1942, RÂ²: 0.1501
lstm_model.compile(optimizer='adam', loss='mse')

# EarlyStopping ì½œë°± ì„¤ì •
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# LSTM ëª¨ë¸ í•™ìŠµ (EarlyStopping ì ìš©)
# ëª¨ë¸ ì„±ëŠ¥ ë†’ì´ê¸° - ë°°ì¹˜í¬ê¸° ì¡°ì •,  ì—í¬í¬ ìˆ˜ up -> ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ì¡°ê¸° ì¢…ë£Œ ì‚¬ìš©
lstm_model.fit(X_train_lstm, y_train, epochs=100, batch_size=16, verbose=1,validation_data=(X_test_lstm, y_test), callbacks=[early_stop])

# LSTM ì˜ˆì¸¡
y_pred_lstm = lstm_model.predict(X_test_lstm).flatten()

# ğŸ”¹ ëª¨ë¸ë³„ ì„±ëŠ¥ í‰ê°€ (MSE, RMSE, RÂ²)
# MSE: ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì˜ ì°¨ì´ë¥¼ ì œê³±í•œ í›„ í‰ê· í•œ ê°’ìœ¼ë¡œ, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
# RMSE: MSEì˜ ì œê³±ê·¼ìœ¼ë¡œ, ì‹¤ì œê°’ì˜ ë‹¨ìœ„ì™€ ë™ì¼í•˜ë©°, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
# RÂ²: ëª¨ë¸ì´ ì‹¤ì œ ë°ì´í„°ì˜ ë¶„ì‚°ì„ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ë©°, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸
lr_mse = mean_squared_error(y_test, y_pred_lr)
lr_rmse = np.sqrt(lr_mse)
lr_r2 = r2_score(y_test, y_pred_lr)

rf_mse = mean_squared_error(y_test, y_pred_rf)
rf_rmse = np.sqrt(rf_mse)
rf_r2 = r2_score(y_test, y_pred_rf)

lstm_mse = mean_squared_error(y_test, y_pred_lstm)
lstm_rmse = np.sqrt(lstm_mse)
lstm_r2 = r2_score(y_test, y_pred_lstm)

# ê²°ê³¼ ì¶œë ¥
print("\nğŸ”¹ ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ")
print(f"ì„ í˜• íšŒê·€ MSE: {lr_mse:.4f}, RMSE: {lr_rmse:.4f}, RÂ²: {lr_r2:.4f}")
print(f"ëœë¤ í¬ë ˆìŠ¤íŠ¸ MSE: {rf_mse:.4f}, RMSE: {rf_rmse:.4f}, RÂ²: {rf_r2:.4f}")
print(f"LSTM MSE: {lstm_mse:.4f}, RMSE: {lstm_rmse:.4f}, RÂ²: {lstm_r2:.4f}")



"""# **ëŸ°íƒ€ì„ ì¢…ë£Œëœ í›„ì—ë„ ëª¨ë¸ ì¬ì‚¬ìš©**
- ë””ìŠ¤í¬ ì €ì¥
- ë¶ˆëŸ¬ì˜¤ê¸°
"""

import joblib

# ëª¨ë¸ ì €ì¥
joblib.dump(lr_model, 'linear_regression_model.pkl')
joblib.dump(rf_model, 'random_forest_model.pkl')

# í•„ìš”ì‹œ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ (LSTM ë°ì´í„° ì •ê·œí™”ìš©)
joblib.dump(scaler, 'scaler.pkl')

# LSTM ëª¨ë¸ ì €ì¥ (HDF5 í¬ë§·)
lstm_model.save('lstm_model.keras')

import joblib

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
lr_model_loaded = joblib.load('linear_regression_model.pkl')
rf_model_loaded = joblib.load('random_forest_model.pkl')

# ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°
scaler_loaded = joblib.load('scaler.pkl')

from tensorflow.keras.models import load_model
# LSTM ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
lstm_model_loaded = load_model('lstm_model.keras')

"""# **í•™ìŠµ ì™„ë£Œ í›„ ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰**"""

# í•™ìŠµ ì™„ë£Œ í›„ ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰

# 1) ëª¨ë¸ í•™ìŠµ í›„, ì „ì²´ Xì— ëŒ€í•´ ì˜ˆì¸¡
X_scaled_all = scaler.transform(X)  # LSTM ìŠ¤ì¼€ì¼ë§
X_scaled_all_lstm = X_scaled_all.reshape((X_scaled_all.shape[0], X_scaled_all.shape[1], 1))

all_pred_lr = lr_model.predict(X)
all_pred_rf = rf_model.predict(X)
all_pred_lstm = lstm_model.predict(X_scaled_all_lstm).flatten()

# 2) ì›ë³¸ ë°ì´í„°ì™€ í•©ì¹˜ê¸°
data_all_pred = data.copy()
data_all_pred['ì„ í˜•íšŒê·€_ì „ì²´ì˜ˆì¸¡'] = all_pred_lr
data_all_pred['ëœë¤í¬ë ˆìŠ¤íŠ¸_ì „ì²´ì˜ˆì¸¡'] = all_pred_rf
data_all_pred['LSTM_ì „ì²´ì˜ˆì¸¡'] = all_pred_lstm

# 3) CSVë¡œ ì €ì¥í•˜ê±°ë‚˜ íŠ¹ì • ì›¹íˆ°ë§Œ í•„í„°ë§í•˜ì—¬ ì‹œê°í™”
data_all_pred.to_csv("prediction_all.csv", index=False)

"""# **ì‹¤ì œ ë³„ì  VS ì˜ˆì¸¡ ë³„ì **"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
from tabulate import tabulate

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (ì˜ˆì¸¡ ê²°ê³¼ í¬í•¨ëœ ë°ì´í„°)
df = pd.read_csv("prediction_all.csv")

# ì‹¤ì œ ë³„ì ê³¼ ì˜ˆì¸¡ëœ ë³„ì  ë¹„êµ
models = ["ì„ í˜•íšŒê·€_ì „ì²´ì˜ˆì¸¡", "ëœë¤í¬ë ˆìŠ¤íŠ¸_ì „ì²´ì˜ˆì¸¡", "LSTM_ì „ì²´ì˜ˆì¸¡"]
results = {}

for model in models:
    mse = mean_squared_error(df["ì‹¤ì œë³„ì "], df[model])
    rmse = np.sqrt(mse)
    r2 = r2_score(df["ì‹¤ì œë³„ì "], df[model])
    results[model] = {"MSE": mse, "RMSE": rmse, "RÂ²": r2}

# ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
results_df = pd.DataFrame(results).T

# ì„±ëŠ¥ ë¹„êµ ì¶œë ¥
print("\nğŸ”¹ ì‹¤ì œ ë³„ì  vs ì˜ˆì¸¡ ë³„ì  ì„±ëŠ¥ ë¹„êµ")
print(tabulate(results_df, headers="keys", tablefmt="pretty", floatfmt=".4f"))

# ì‹œê°í™” - ì‹¤ì œ ë³„ì ê³¼ ì˜ˆì¸¡ ë³„ì  ë¹„êµ
plt.figure(figsize=(12, 6))
sns.lineplot(x=df["í™”ë²ˆí˜¸"], y=df["ì‹¤ì œë³„ì "], label="ì‹¤ì œë³„ì ", marker="o", linestyle="-")
for model in models:
    sns.lineplot(x=df["í™”ë²ˆí˜¸"], y=df[model], label=model, linestyle="--")

plt.xlabel("ì—í”¼ì†Œë“œ ë²ˆí˜¸")
plt.ylabel("ë³„ì ")
plt.title("ì‹¤ì œ ë³„ì  vs ì˜ˆì¸¡ ë³„ì  ë¹„êµ")
plt.legend()
plt.grid()
plt.show()

"""# **ì‹œê°í™” ê·¸ë˜í”„: ì—í”¼ì†Œë“œ ë³„ ì˜ˆì¸¡ í‰ì  vs ì‹¤ì œ í‰ì **"""

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from matplotlib import rc

# í°íŠ¸ íŒŒì¼ ê²½ë¡œ ì§€ì • ë° í°íŠ¸ ì¶”ê°€
font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
fm.fontManager.addfont(font_path)
plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

print("íŒŒì¼ ë‚´ ì¡´ì¬í•˜ëŠ” ì›¹íˆ°ID ëª©ë¡:")
print(data_all_pred["ì›¹íˆ°"].unique())  # ì›¹íˆ°ID ëª©ë¡ ì¶œë ¥

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
data_all_pred = pd.read_csv("prediction_all.csv")

# ì‚¬ìš©ì ì…ë ¥ë°›ê¸°
selected_webtoon = int(input("ì„ íƒí•  ì›¹íˆ°IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))

# ì›¹íˆ°ID í•„í„°ë§ (ìˆ«ìë¡œ ë³€í™˜)
webtoon_df = data_all_pred[data_all_pred['ì›¹íˆ°'] == selected_webtoon].copy()

# í™”ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ í›„ ì •ë ¬
webtoon_df = data_all_pred[data_all_pred['ì›¹íˆ°'] == selected_webtoon].copy()

# í™”ë²ˆí˜¸ê°€ ì •ìˆ˜í˜•ì´ë©´ ì •ë ¬ ê°€ëŠ¥
if webtoon_df['í™”ë²ˆí˜¸'].dtype == 'O':  # 'O'ëŠ” object(ë¬¸ìì—´) íƒ€ì…
    webtoon_df['í™”ë²ˆí˜¸'] = pd.to_numeric(webtoon_df['í™”ë²ˆí˜¸'], errors='coerce')

webtoon_df = webtoon_df.sort_values(by='í™”ë²ˆí˜¸')  # í™”ë²ˆí˜¸ ê¸°ì¤€ ì •ë ¬

# ğŸ”¹ í•„í„°ë§ ë° ì •ë ¬ëœ ë°ì´í„° í™•ì¸
print(tabulate(webtoon_df.head(), headers="keys", tablefmt="pretty", floatfmt=".4f"))
plt.figure(figsize=(12, 6))

# ëª¨ë¸ë³„ ì˜ˆì¸¡ê°’ (ì„ í˜• íšŒê·€, ëœë¤ í¬ë ˆìŠ¤íŠ¸, LSTM)
plt.plot(webtoon_df['í™”ë²ˆí˜¸'], webtoon_df['ì„ í˜•íšŒê·€_ì „ì²´ì˜ˆì¸¡'], marker='o', label='ì„ í˜• íšŒê·€ ì˜ˆì¸¡')
plt.plot(webtoon_df['í™”ë²ˆí˜¸'], webtoon_df['ëœë¤í¬ë ˆìŠ¤íŠ¸_ì „ì²´ì˜ˆì¸¡'], marker='s', label='ëœë¤ í¬ë ˆìŠ¤íŠ¸ ì˜ˆì¸¡')
plt.plot(webtoon_df['í™”ë²ˆí˜¸'], webtoon_df['LSTM_ì „ì²´ì˜ˆì¸¡'], marker='^', label='LSTM ì˜ˆì¸¡')

# ì‹¤ì œ ë³„ì  (ì‹¤ì œ ê°’ì€ ê²€ì€ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
plt.plot(webtoon_df['í™”ë²ˆí˜¸'], webtoon_df['ì‹¤ì œë³„ì '], marker='x', linestyle='--',linewidth=2, color='black', label='ì‹¤ì œ ë³„ì ')

plt.xlabel("ì—í”¼ì†Œë“œ ë²ˆí˜¸")
plt.ylabel("í‰ì ")
plt.title(f"{selected_webtoon} ì—í”¼ì†Œë“œ ë³„ ì˜ˆì¸¡ í‰ì  vs ì‹¤ì œ í‰ì ")
plt.legend()
plt.grid(True)
plt.show()

# -------------------------------------------
# A. ê°ì„± íŠ¸ë Œë“œ ì‹œê³„ì—´ ë¶„ì„ (ì—í”¼ì†Œë“œë³„ ê°ì„± ë¹„ìœ¨ ë³€í™”)
# -------------------------------------------
# íŠ¹ì • ì›¹íˆ° ì„ íƒ (ì˜ˆ: 'ì›¹íˆ°1') í›„, ì—í”¼ì†Œë“œë³„ ê°ì„± ë¹„ìœ¨ ë³€í™” ì„  ê·¸ë˜í”„

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
data_all_pred = pd.read_csv("prediction_all.csv")

# ì‚¬ìš©ì ì…ë ¥ë°›ê¸°
selected_webtoon = int(input("ì„ íƒí•  ì›¹íˆ°IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))

# ì›¹íˆ°ID í•„í„°ë§ (ìˆ«ìë¡œ ë³€í™˜)
webtoon_df = data_all_pred[data_all_pred['ì›¹íˆ°'] == selected_webtoon].copy()

# í™”ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ í›„ ì •ë ¬
webtoon_df = data_all_pred[data_all_pred['ì›¹íˆ°'] == selected_webtoon].copy()

# í™”ë²ˆí˜¸ê°€ ì •ìˆ˜í˜•ì´ë©´ ì •ë ¬ ê°€ëŠ¥
if webtoon_df['í™”ë²ˆí˜¸'].dtype == 'O':  # 'O'ëŠ” object(ë¬¸ìì—´) íƒ€ì…
    webtoon_df['í™”ë²ˆí˜¸'] = pd.to_numeric(webtoon_df['í™”ë²ˆí˜¸'], errors='coerce')

webtoon_df = webtoon_df.sort_values(by='í™”ë²ˆí˜¸')  # í™”ë²ˆí˜¸ ê¸°ì¤€ ì •ë ¬


plt.figure(figsize=(10, 6))
plt.plot(webtoon_df['í™”ë²ˆí˜¸'], webtoon_df['ê¸ì •ë¹„ìœ¨'], marker='o', label='ê¸ì •ë¹„ìœ¨')
plt.plot(webtoon_df['í™”ë²ˆí˜¸'], webtoon_df['ë¶€ì •ë¹„ìœ¨'], marker='s', label='ë¶€ì •ë¹„ìœ¨')
plt.xlabel("í™” ë²ˆí˜¸")
plt.ylabel("ë¹„ìœ¨")
plt.title(f"{selected_webtoon} ê°ì„± íŠ¸ë Œë“œ (ì—í”¼ì†Œë“œë³„ ê°ì„± ë¹„ìœ¨)")
plt.legend()
plt.grid(True)
plt.show()

# -------------------------------------------
# B. í‰ì  ë¶„í¬ ë° í†µê³„ ë¹„êµ (ë°•ìŠ¤ í”Œë¡¯ / ë°”ì´ì˜¬ë¦° í”Œë¡¯)
# -------------------------------------------
# ì—¬ê¸°ì„œëŠ” ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì‹¤ì œ ë³„ì ê³¼ ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ ì „ì²´ ì˜ˆì¸¡ê°’ ë¶„í¬ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
# ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì„ í˜• íšŒê·€ ì˜ˆì¸¡ ìˆ˜í–‰ (ì´ë¯¸ lr_modelì€ í•™ìŠµë˜ì—ˆë‹¤ê³  ê°€ì •)
# ë§Œì•½ lr_modelì´ ì´ë¯¸ í•™ìŠµëœ ìƒíƒœë¼ë©´:
all_pred_lr = lr_model.predict(data[['ê¸ì •ë¹„ìœ¨', 'ë¶€ì •ë¹„ìœ¨']])

# ê²°ê³¼ DataFrameì— ì˜ˆì¸¡ê°’ ì¶”ê°€
data_all = data.copy()
data_all['ì„ í˜•íšŒê·€_ì „ì²´ì˜ˆì¸¡'] = all_pred_lr

plt.figure(figsize=(10, 6))
sns.boxplot(data=data_all[['ì‹¤ì œë³„ì ', 'ì„ í˜•íšŒê·€_ì „ì²´ì˜ˆì¸¡']])
plt.title("ì „ì²´ ë°ì´í„° ë³„ì  ë¶„í¬ ë¹„êµ (ì‹¤ì œ vs ì„ í˜•íšŒê·€ ì˜ˆì¸¡)")
plt.ylabel("í‰ì ")
plt.show()

# ë˜ëŠ” ë°”ì´ì˜¬ë¦° í”Œë¡¯ìœ¼ë¡œ ë¶„í¬ ë¹„êµ
plt.figure(figsize=(10, 6))
sns.violinplot(data=data_all[['ì‹¤ì œë³„ì ', 'ì„ í˜•íšŒê·€_ì „ì²´ì˜ˆì¸¡']])
plt.title("ì „ì²´ ë°ì´í„° ë³„ì  ë¶„í¬ ë¹„êµ (ì‹¤ì œ vs ì„ í˜•íšŒê·€ ì˜ˆì¸¡)")
plt.ylabel("í‰ì ")
plt.show()

# -------------------------------------------
# B. í‰ì  ë¶„í¬ ë° í†µê³„ ë¹„êµ (ë°•ìŠ¤ í”Œë¡¯ / ë°”ì´ì˜¬ë¦° í”Œë¡¯)
# -------------------------------------------
# ì—¬ê¸°ì„œëŠ” ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì‹¤ì œ ë³„ì ê³¼ ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì˜ ì „ì²´ ì˜ˆì¸¡ê°’ ë¶„í¬ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
# ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ëœë¤í¬ë ˆìŠ¤íŠ¸ ì˜ˆì¸¡ ìˆ˜í–‰ (ì´ë¯¸ lr_modelì€ í•™ìŠµë˜ì—ˆë‹¤ê³  ê°€ì •)
# ë§Œì•½ lr_modelì´ ì´ë¯¸ í•™ìŠµëœ ìƒíƒœë¼ë©´:
all_pred_rf = lr_model.predict(data[['ê¸ì •ë¹„ìœ¨', 'ë¶€ì •ë¹„ìœ¨']])

# ê²°ê³¼ DataFrameì— ì˜ˆì¸¡ê°’ ì¶”ê°€
data_all = data.copy()
data_all['ë¨ë¤í¬ë ˆìŠ¤íŠ¸_ì „ì²´ì˜ˆì¸¡'] = all_pred_rf

plt.figure(figsize=(10, 6))
sns.boxplot(data=data_all[['ì‹¤ì œë³„ì ', 'ë¨ë¤í¬ë ˆìŠ¤íŠ¸_ì „ì²´ì˜ˆì¸¡']])
plt.title("ì „ì²´ ë°ì´í„° ë³„ì  ë¶„í¬ ë¹„êµ (ì‹¤ì œ vs ë¨ë¤í¬ë ˆìŠ¤íŠ¸ ì˜ˆì¸¡)")
plt.ylabel("í‰ì ")
plt.show()

# ë˜ëŠ” ë°”ì´ì˜¬ë¦° í”Œë¡¯ìœ¼ë¡œ ë¶„í¬ ë¹„êµ
plt.figure(figsize=(10, 6))
sns.violinplot(data=data_all[['ì‹¤ì œë³„ì ', 'ë¨ë¤í¬ë ˆìŠ¤íŠ¸_ì „ì²´ì˜ˆì¸¡']])
plt.title("ì „ì²´ ë°ì´í„° ë³„ì  ë¶„í¬ ë¹„êµ (ì‹¤ì œ vs ë¨ë¤í¬ë ˆìŠ¤íŠ¸ ì˜ˆì¸¡)")
plt.ylabel("í‰ì ")
plt.show()

# -------------------------------------------
# B. í‰ì  ë¶„í¬ ë° í†µê³„ ë¹„êµ (ë°•ìŠ¤ í”Œë¡¯ / ë°”ì´ì˜¬ë¦° í”Œë¡¯)
# -------------------------------------------
# ì—¬ê¸°ì„œëŠ” ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì‹¤ì œ ë³„ì ê³¼ LSTM ëª¨ë¸ì˜ ì „ì²´ ì˜ˆì¸¡ê°’ ë¶„í¬ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
# ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ LSTM ì˜ˆì¸¡ ìˆ˜í–‰ (ì´ë¯¸ lr_modelì€ í•™ìŠµë˜ì—ˆë‹¤ê³  ê°€ì •)
# ë§Œì•½ lr_modelì´ ì´ë¯¸ í•™ìŠµëœ ìƒíƒœë¼ë©´:
all_pred_lstm = lr_model.predict(data[['ê¸ì •ë¹„ìœ¨', 'ë¶€ì •ë¹„ìœ¨']])

# ê²°ê³¼ DataFrameì— ì˜ˆì¸¡ê°’ ì¶”ê°€
data_all = data.copy()
data_all['LSTM_ì „ì²´ì˜ˆì¸¡'] = all_pred_lstm

plt.figure(figsize=(10, 6))
sns.boxplot(data=data_all[['ì‹¤ì œë³„ì ', 'LSTM_ì „ì²´ì˜ˆì¸¡']])
plt.title("ì „ì²´ ë°ì´í„° ë³„ì  ë¶„í¬ ë¹„êµ (ì‹¤ì œ vs LSTM ì˜ˆì¸¡)")
plt.ylabel("í‰ì ")
plt.show()

# ë˜ëŠ” ë°”ì´ì˜¬ë¦° í”Œë¡¯ìœ¼ë¡œ ë¶„í¬ ë¹„êµ
plt.figure(figsize=(10, 6))
sns.violinplot(data=data_all[['ì‹¤ì œë³„ì ', 'LSTM_ì „ì²´ì˜ˆì¸¡']])
plt.title("ì „ì²´ ë°ì´í„° ë³„ì  ë¶„í¬ ë¹„êµ (ì‹¤ì œ vs LSTM ì˜ˆì¸¡)")
plt.ylabel("í‰ì ")
plt.show()

# -------------------------------------------
# C. ì˜¤ì°¨(Residual) ë¶„ì„
# -------------------------------------------
# ì—¬ê¸°ì„œëŠ” í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ì„ í˜• íšŒê·€ì˜ ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ë¶„ì„í•œë‹¤ê³  ê°€ì • (comparison_df ì‚¬ìš©)
# ë§Œì•½ comparison_dfê°€ ì´ë¯¸ ì¡´ì¬í•œë‹¤ë©´, ì˜¤ì°¨ë¥¼ ê³„ì‚°í•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ì„ ì¶”ê°€
# (ì˜¤ì°¨ = ì‹¤ì œë³„ì  - ì˜ˆì¸¡ë³„ì )

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
data_all_pred = pd.read_csv("prediction_all.csv")

# ì‚¬ìš©ì ì…ë ¥ë°›ê¸°
selected_webtoon = int(input("ì„ íƒí•  ì›¹íˆ°IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))

# ì›¹íˆ°ID í•„í„°ë§ (ìˆ«ìë¡œ ë³€í™˜)
webtoon_df = data_all_pred[data_all_pred['ì›¹íˆ°'] == selected_webtoon].copy()

# í™”ë²ˆí˜¸ê°€ ì •ìˆ˜í˜•ì´ë©´ ì •ë ¬ ê°€ëŠ¥
if webtoon_df['í™”ë²ˆí˜¸'].dtype == 'O':  # 'O'ëŠ” object(ë¬¸ìì—´) íƒ€ì…
    webtoon_df['í™”ë²ˆí˜¸'] = pd.to_numeric(webtoon_df['í™”ë²ˆí˜¸'], errors='coerce')

webtoon_df = webtoon_df.sort_values(by='í™”ë²ˆí˜¸')  # í™”ë²ˆí˜¸ ê¸°ì¤€ ì •ë ¬

# ì˜¤ì°¨ ì»¬ëŸ¼ ì¶”ê°€ (ì˜¤ì°¨ = ì‹¤ì œë³„ì  - ì˜ˆì¸¡ë³„ì )
data_all_pred['ì˜¤ì°¨'] = data_all_pred['ì‹¤ì œë³„ì '] - data_all_pred['ì„ í˜•íšŒê·€_ì „ì²´ì˜ˆì¸¡']

# ì˜¤ì°¨ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
plt.figure(figsize=(10, 6))
plt.hist(data_all_pred['ì˜¤ì°¨'], bins=30, color='skyblue', edgecolor='black')
plt.title("ì„ í˜• íšŒê·€ ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬ (ì „ì²´ ë°ì´í„°)")
plt.xlabel("ì˜¤ì°¨ (ì‹¤ì œë³„ì  - ì˜ˆì¸¡ë³„ì )")
plt.ylabel("ë¹ˆë„")
plt.show()

# ì˜¤ì°¨ ì‚°ì ë„ (íŠ¹ì • ì›¹íˆ°ì— ëŒ€í•´)
plt.figure(figsize=(10, 6))
plt.scatter(data_all_pred['í™”ë²ˆí˜¸'], data_all_pred['ì˜¤ì°¨'], color='red')
plt.axhline(0, color='black', linestyle='--')
plt.title(f"{selected_webtoon} ì—í”¼ì†Œë“œë³„ ì˜ˆì¸¡ ì˜¤ì°¨ (ì‹¤ì œ - ì˜ˆì¸¡)")
plt.xlabel("í™” ë²ˆí˜¸")
plt.ylabel("ì˜¤ì°¨")
plt.grid(True)
plt.show()

# -------------------------------------------
# D. ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ (ê°ì„± ì§€í‘œì™€ í‰ì  ê°„)
# -------------------------------------------
# ê°ì„± ë¹„ìœ¨ ë° í‰ì  ê´€ë ¨ ì»¬ëŸ¼ë“¤ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°
corr_cols = ['ê¸ì •ë¹„ìœ¨', 'ë¶€ì •ë¹„ìœ¨', 'ì‹¤ì œë³„ì ']
corr_matrix = data[corr_cols].corr()

plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title("ê°ì„± ë¹„ìœ¨ ë° í‰ì  ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
plt.show()

# -------------------------------------------
# E. ëŒ“ê¸€ í…ìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ (ëŒ“ê¸€ ì›Œë“œ í´ë¼ìš°ë“œ ë° ê¸¸ì´ ë¶„í¬)
# -------------------------------------------
# ë§Œì•½ ë°ì´í„°ì— 'ëŒ“ê¸€' ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì§„í–‰ (ì—†ìœ¼ë©´ ê±´ë„ˆëœë‹ˆë‹¤)
if 'ëŒ“ê¸€' in data.columns:
    from wordcloud import WordCloud

    # ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„± (ì „ì²´ ëŒ“ê¸€)
    all_comments = " ".join(data['ëŒ“ê¸€'].astype(str))
    wc = WordCloud(width=800, height=400, background_color='white').generate(all_comments)
    plt.figure(figsize=(12, 6))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title("ì „ì²´ ëŒ“ê¸€ ì›Œë“œ í´ë¼ìš°ë“œ")
    plt.show()

    # ëŒ“ê¸€ ê¸¸ì´ ë¶„í¬ (ê° ëŒ“ê¸€ì˜ ê¸€ì ìˆ˜)
    data['ëŒ“ê¸€ê¸¸ì´'] = data['ëŒ“ê¸€'].astype(str).apply(len)
    plt.figure(figsize=(10, 6))
    plt.hist(data['ëŒ“ê¸€ê¸¸ì´'], bins=30, color='lightgreen', edgecolor='black')
    plt.title("ëŒ“ê¸€ ê¸¸ì´ ë¶„í¬")
    plt.xlabel("ëŒ“ê¸€ ê¸¸ì´(ê¸€ì ìˆ˜)")
    plt.ylabel("ë¹ˆë„")
    plt.show()
else:
    print("ëŒ“ê¸€ ê´€ë ¨ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ëŒ“ê¸€ í…ìŠ¤íŠ¸ ë¶„ì„ì€ ê±´ë„ˆëœë‹ˆë‹¤.")

# -------------------------------------------
# F. ì›¹íˆ° í´ëŸ¬ìŠ¤í„°ë§ ë° ì°¨ì› ì¶•ì†Œ ì‹œê°í™” (PCA)
# -------------------------------------------
# ê°ì„± ì§€í‘œì™€ í‰ì  ë°ì´í„°ë¥¼ í™œìš©í•´ PCA ìˆ˜í–‰ í›„ ì¥ë¥´ë³„ë¡œ ì‹œê°í™”
# ì‚¬ìš©í•  í”¼ì²˜: 'ê¸ì •ë¹„ìœ¨', 'ë¶€ì •ë¹„ìœ¨', 'ì¤‘ë¦½ë¹„ìœ¨', 'í‰ì ', 'ì‹¤ì œë³„ì '
features = ['ê¸ì •ë¹„ìœ¨', 'ë¶€ì •ë¹„ìœ¨', 'ì‹¤ì œë³„ì ']
pca = PCA(n_components=2)
pca_result = pca.fit_transform(data[features])
data['PCA1'] = pca_result[:, 0]
data['PCA2'] = pca_result[:, 1]

plt.figure(figsize=(10, 6))
# ì¥ë¥´ë³„ë¡œ ìƒ‰ìƒì„ êµ¬ë¶„ (ì¥ë¥´ ì»¬ëŸ¼ì´ ì¡´ì¬í•œë‹¤ê³  ê°€ì •)
if 'ì¥ë¥´' in data.columns:
    genres = data['ì¥ë¥´'].unique()
    for genre in genres:
        subset = data[data['ì¥ë¥´'] == genre]
        plt.scatter(subset['PCA1'], subset['PCA2'], label=genre, alpha=0.6)
    plt.legend()
    plt.title("PCAë¥¼ í™œìš©í•œ ì›¹íˆ° í´ëŸ¬ìŠ¤í„°ë§ (ê°ì„± ë° í‰ì  ê¸°ë°˜)")
else:
    plt.scatter(data['PCA1'], data['PCA2'], alpha=0.6)
    plt.title("PCAë¥¼ í™œìš©í•œ ì›¹íˆ° í´ëŸ¬ìŠ¤í„°ë§")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.grid(True)
plt.show()